# COMP7707 A3 — Real-time IoT Analytics System Prototype
Member A — System Design & Implementation  
Student: Kodnatthaphat Authaianurak (auth0004)  
Dataset: Southern Grampians Shire Council – Weather Sensors (SGSC_Weather_Sensor_Data.csv, time format YYYYMMDDHHMMSS)

---

## 1. Project Overview

This repository provides an end-to-end Real-time IoT Analytics System for COMP7707 Assessment Task 3.  
It loads weather sensor data, detects anomalies with machine learning, and visualizes live results on a dashboard.

Core components
- `prototype.py` — loads/cleans the dataset, trains Isolation Forest and One-Class SVM, simulates a real-time stream, writes to `stream_output.csv`.
- `app.py` — Streamlit dashboard with KPIs, feature charts, anomaly table, and auto-refresh.

---

## 2. System Architecture (ASCII)

Input CSV  -->  Load + Clean + Parse Time + Filter Years (2018–2021)
                   |
                   v
             TRAIN (first 70%, time-ordered)
             - Isolation Forest
             - One-Class SVM (with StandardScaler)
                   |
                   v
             STREAM (last 30%, optional synthetic anomalies)
             - Predict IF_Flag and OC_Flag per record
             - Buffer and append results to CSV in chunks
                   |
                   v
             stream_output.csv  <---- read continuously ----  app.py (Streamlit)
                                                         - KPIs, charts, anomaly table

---

## 3. Features

3.1 prototype.py
- Robust time parsing for YYYYMMDDHHMMSS (handles strings, integers, scientific notation like 2.01808E+13).
- Strict year filter: 2018–2021.
- Automatic feature selection from relevant numeric columns (prefers: airtemp, relativehumidity, windspeed, solar, vapourpressure, atmosphericpressure, gustspeed, winddirection).
- Models:
  - Isolation Forest (contamination=0.05, n_estimators=200)
  - One-Class SVM (kernel=rbf, nu=0.05, gamma=scale) with StandardScaler
- Real-time stream simulation: appends every 10 rows to reduce partial reads.
- Optional synthetic anomaly injection for end-to-end testing.
- Time-ordered train/stream split (70/30) to avoid temporal leakage.

3.2 app.py
- Fixed grid layout; metric cards aligned and equal width.
- KPIs: Total Records, IF Alerts, OCSVM Alerts, Synthetic Anomalies, Model Agreement (%), Anomaly Ratio (%), CPU (%), Memory (MB), File Size (KB).
- Interactive charts (multiselect features). Uses width='stretch'.
- Anomaly table showing latest flagged rows.
- Sidebar controls: auto-refresh toggle, refresh interval, rows window, show/hide table, show all features.

---

## 4. File Structure

COMP7707_A3/
- prototype.py
- app.py
- SGSC_Weather_Sensor_Data.csv  (auto-downloaded if missing)
- stream_output.csv             (generated by prototype.py)
- README.md

---

## 5. Setup and Quick Start

5.1 Requirements
- Python 3.9+ (tested on 3.10–3.12)
- Virtual environment recommended (venv or conda)

5.2 Install dependencies
pip install -r requirements.txt

5.3 Run streaming backend
python prototype.py

This will:
- Load (or download) the dataset.
- Clean and parse time; filter to 2018–2021.
- Split by time: first 70% train, last 30% stream.
- Train Isolation Forest and One-Class SVM.
- Start streaming and append results to stream_output.csv.

5.4 Run dashboard
streamlit run app.py

Open the URL printed in terminal (usually http://localhost:8501).

---

## 6. Key Parameters (prototype.py)

TRAIN_RATIO   = 0.7        # time-ordered split (train then stream)
CONTAMINATION = 0.05       # Isolation Forest expected anomaly ratio
NU_VAL        = 0.05       # One-Class SVM nu (outlier bound)
STREAM_DELAY  = 0.2        # seconds per record (stream simulation)
SAMPLE_SIZE   = 10000      # cap rows for fast demo; keeps earliest rows
SYNTHETIC     = True       # enable synthetic anomaly injection
SYNTH_POINTS  = 150        # number of injected anomalies
RANDOM_SEED   = 42         # reproducibility
YEAR_START    = 2018
YEAR_END      = 2021

---

## 7. Data Cleaning and Time Parsing

- Lower-case and trim column names.
- Detect and rename time column to "time" if necessary.
- Convert to datetime:
  - Coerce scientific notation / floats / ints to 14-digit strings.
  - Remove non-digits; require exactly 14 digits (YYYYMMDDHHMMSS).
  - Use pandas to_datetime with errors='coerce'.
- Drop rows with invalid time; sort by time ascending.
- Filter rows where time.year in [2018, 2019, 2020, 2021].
- Select numeric features; forward/backward fill missing values.
- If dataset is large, keep head(SAMPLE_SIZE) to start from earliest times.

---

## 8. Model Training and Streaming

- Training uses only the earliest section (first 70%) to respect temporal ordering.
- Isolation Forest fits directly on raw features.
- One-Class SVM uses StandardScaler; fits on scaled features.
- During streaming, for each new record:
  - Compute IF_Flag and OC_Flag (1 for anomaly, 0 for normal).
  - Preserve ground truth synthetic label as GT_Label (0 or 1).
  - Append to CSV in batches of 10 rows to minimize dashboard flicker.
- The CSV columns are: Index, Time, <features...>, IF_Flag, OC_Flag, GT_Label.

---

## 9. Dashboard Usage (app.py)

- Controls:
  - Auto-refresh: on/off, refresh interval (2–20 seconds).
  - Rows window (50–1000) used for charts and metrics.
  - Show anomaly table toggle.
  - Show all features toggle; otherwise select features via multiselect.
- KPIs (top rows):
  - Total Records, IF Alerts, OCSVM Alerts, Synthetic Anomalies, File Size (KB).
  - Model Agreement (%) = proportion where IF_Flag=1 and OC_Flag=1.
  - Anomaly Ratio (%) = union(IF_Flag, OC_Flag) / window_size.
  - CPU usage (%) and Memory (MB).
- Charts:
  - Line charts indexed by Time for selected numeric features.
- Table:
  - Shows the latest rows with IF_Flag=1 or OC_Flag=1.

---

## 10. Reproducibility

- Global random seed (NumPy/scikit-learn): 42.
- Deterministic time-ordered splitting.
- Consistent cleaning and feature pipeline.

---

## 11. Roles and Contributions

- Member A (this repository): system design, data cleaning pipeline, model training code, streaming simulation, Streamlit dashboard layout and KPIs.
- Member B: analysis, model evaluation and tuning (external to this codebase).
- Member C: documentation and integration testing (external to this codebase).

---

## 12. Troubleshooting

- Dashboard does not update:
  - Ensure `prototype.py` is running and `stream_output.csv` exists and is growing.
  - Increase refresh interval in sidebar; ensure auto-refresh is enabled.
- Missing columns IF_Flag or OC_Flag:
  - The CSV is only produced by `prototype.py`; re-run it to regenerate.
- Time parsing removed all rows:
  - Confirm the dataset time format matches YYYYMMDDHHMMSS.
  - Remove SAMPLE_SIZE cap for debugging and print sample values.
- High CPU usage:
  - Increase STREAM_DELAY, reduce rows window, or disable show all features.

---

## 13. References

- Southern Grampians Shire Council Weather Dataset — data.gov.au
- Pedregosa et al., 2011. Scikit-learn: Machine Learning in Python. JMLR.
- General references on Isolation Forest and One-Class SVM (standard documentation).

---

## 14. Academic Integrity and AI Usage Declaration

In accordance with COMP7707 AI policy, AI tools were used for idea structuring and documentation formatting only. Source code submitted for assessment reflects the student’s own implementation.
